{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85fe6a36",
   "metadata": {},
   "source": [
    "# 1. Integrácia dát (3b)\n",
    "\n",
    "- Integrácia datasetu - vhodne zakomponujte zvolené informácie o počasí.\n",
    "- Sampling – vytvorenie vzorky z datasetu (veľkosti napr. 10%) pri zachovaní rozloženia cieľového atribútu.\n",
    "- Rozdelenie datasetu na trénovaciu a testovaciu množinu (napr. v pomere 60/40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a110c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fddabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_files(spark: SparkSession, file_paths: list[str], infer_schema:bool=True, header:bool=True, on:str=\"id\", how:str=\"inner\") -> DataFrame:\n",
    "    if len(file_paths) == 0:\n",
    "        schema = StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True)\n",
    "        ])\n",
    "        df = spark.createDataFrame([],schema)\n",
    "    else:\n",
    "        df = spark.read.csv(file_paths[0], header=header, inferSchema=infer_schema)\n",
    "        for idx in range(1,len(file_paths)):\n",
    "            file = spark.read.csv(file_paths[idx], header=header, inferSchema=infer_schema)\n",
    "            df = df.join(file, on=on, how=how)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1fa58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_by_percent(df: DataFrame, label: str, percent: float) -> DataFrame:\n",
    "    fractions = df.select(label).distinct().rdd.map(lambda r: (r[0], percent)).collectAsMap()\n",
    "    return df.stat.sampleBy(label, fractions, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c55de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"CarAccidents\").getOrCreate()\n",
    "\n",
    "file_list = [\n",
    "    \"../datalab/TSVD/dataset/CarAccidents/Accidents.csv\",\n",
    "    \"../datalab/TSVD/dataset/CarAccidents/Casualties.csv\",\n",
    "    \"../datalab/TSVD/dataset/CarAccidents/Vehicles.csv\"\n",
    "]\n",
    "\n",
    "df = read_csv_files(spark, file_list, on=\"Accident_Index\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampled_data = sample_by_percent(df,\"Accident_Severity\",0.1)\n",
    "print(f\"Prcent for sample data: {(sampled_data.count()/df.count())*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df.randomSplit([0.6, 0.4], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be152884",
   "metadata": {},
   "source": [
    "# 2. Predspracovanie (7b)\n",
    "\n",
    "- Transformácia nominálnych atribútov na numerické\n",
    "- Transformácia numerických atribútov na nominálne\n",
    "- Vypočítanie pomerového kritéria – informačného zisku voči cieľovému atribútu (klasifikačná úloha), pre nominálne atribúty\n",
    "- Vypočítanie štatistík pre numerické atribúty\n",
    "- Vytvorenie histogramov pre nominálne atribúty\n",
    "- Spracovanie chýbajúcich hodnôt (napr. ich nahradenie priemermi, atď.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79dd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deae4f76",
   "metadata": {},
   "source": [
    "# 3. Modelovanie - Vytvorenie popisných modelov (3b):\n",
    "\n",
    "- Vytvorte k-means clustering model\n",
    "- Pomocou vytvoreného modelu detekujte anomálie\n",
    "# 4. Modelovanie - Vytvorenie klasifikačných modelov typu (aspoň jeden model každého typu)(4b):\n",
    "\n",
    "- Decision tree model\n",
    "- Linear SVM\n",
    "- Naive Bayes model\n",
    "- Ensembles of decision trees (Random Forests, Gradient-boosted trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b7af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2754253",
   "metadata": {},
   "source": [
    "# 5. Vyhodnotenie (3b)\n",
    "\n",
    "- Natrénovanie klasifikačného modelu na trénovacej množine a jeho evaluáciu na testovacej množine.\n",
    "- Klasifikačný model vyhodnocujte použitím kontigenčnej tabuľky a vypočítaním metrík presnosti, návratnosti, F1 a MCC (Matthews Correlation Coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561e288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
